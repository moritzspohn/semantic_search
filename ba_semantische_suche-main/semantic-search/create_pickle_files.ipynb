{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the pickle file for the individual calculations semantic search object\n",
    "### <span style=\"color:red\">This has to be done only once if the file does not exist in the temporary-storage folder</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from search_individual_calculations import SemanticSearchIndividualCalculations\n",
    "\n",
    "# The data to be pickled\n",
    "semantic_search_object = SemanticSearchIndividualCalculations()\n",
    "\n",
    "# Save the data to a pickle file\n",
    "with open(\"./temporary-storage/semantic-search-object-individual-calculations.pkl\", \"wb\") as file:\n",
    "    pickle.dump(semantic_search_object, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following code is for the precalculated ontology and the secound search algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the dictionary of the competencies for all publications\n",
    "#### This process has been outsourced from the class SemanticSearch because it it very computationally expensive. This way it can be done asynchronously.\n",
    "## <span style=\"color:red\">Warning, this process typically takes ~1-2 hours</span>\n",
    "#### <span style=\"color:red\">It has to be done only a single time if the all-publications-competencies-dict.json file has not been created yet</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from search_precalculated import SemanticSearchPrecalculated\n",
    "\n",
    "def ask_for_confirmation():\n",
    "    while True:\n",
    "        user_input = input(\"Are you sure? (yes/no): \").strip().lower()\n",
    "        if user_input == \"yes\":\n",
    "            return True\n",
    "        elif user_input == \"no\":\n",
    "            return False\n",
    "        else:\n",
    "            print(\"Invalid input. Please type 'yes' or 'no'.\")\n",
    "\n",
    "# Call the function to ask for confirmation\n",
    "resume_code = ask_for_confirmation()\n",
    "\n",
    "if resume_code:\n",
    "    # Initialize a SemanticSearch object\n",
    "    search = SemanticSearchPrecalculated('../ontology/semantic-search-ontology.rdf')\n",
    "    # Generate a list of all existing publication_urns\n",
    "    all_publications = search.get_all_publications()\n",
    "\n",
    "    all_publications_competencies = {}\n",
    "\n",
    "    # Iterate over all publications to determine their competencies\n",
    "    for current_publication in tqdm(all_publications):\n",
    "        # Save the current publication's competencies\n",
    "        all_publications_competencies[current_publication] = search.get_competencies_of_publication((1, current_publication), 0).to_ordered_list()\n",
    "\n",
    "    # Save the competencies of all the publications in a json file\n",
    "    with open('./temporary-storage/all-publications-competencies-dict.json', 'w') as file:\n",
    "        json.dump(all_publications_competencies, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating all similarities for all publication pairs\n",
    "### Then saving them in the ontology\n",
    "#### <span style=\"color:red\">This has to be done only a single time if the semantic-search-ontology-precalculated-similarities.rdf file has not been created yet</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from search_precalculated import SemanticSearchPrecalculated\n",
    "\n",
    "def ask_for_confirmation():\n",
    "    while True:\n",
    "        user_input = input(\"Are you sure? (yes/no): \").strip().lower()\n",
    "        if user_input == \"yes\":\n",
    "            return True\n",
    "        elif user_input == \"no\":\n",
    "            return False\n",
    "        else:\n",
    "            print(\"Invalid input. Please type 'yes' or 'no'.\")\n",
    "\n",
    "# Call the function to ask for confirmation\n",
    "resume_code = ask_for_confirmation()\n",
    "\n",
    "if resume_code:\n",
    "    # Initilize a SemanticSearch object to generate the new ontology\n",
    "    helper_search = SemanticSearchPrecalculated('../ontology/semantic-search-ontology.rdf')\n",
    "\n",
    "    # Load the competencies of all publications dictionary from the json file\n",
    "    with open('./temporary-storage/all-publications-competencies-dict.json', 'r') as file:\n",
    "        all_publications_competencies_list_dict = json.load(file)\n",
    "\n",
    "    # Build and save the resulting ontology that contains direct similarities between publications\n",
    "    helper_search.add_all_publication_pairs_to_ontology(all_publications_competencies_list_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the pickle file for the precalculated semantic search object\n",
    "### <span style=\"color:red\">This has to be done only once if the file does not exist in the temporary-storage folder</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from search_precalculated import SemanticSearchPrecalculated\n",
    "\n",
    "# The data to be pickled\n",
    "semantic_search_object_precalculated = SemanticSearchPrecalculated()\n",
    "\n",
    "# Save the data to a pickle file\n",
    "with open(\"./temporary-storage/semantic-search-object-precalculated.pkl\", \"wb\") as file:\n",
    "    pickle.dump(semantic_search_object_precalculated, file)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
